# sign2speak

## ğŸš€ Overview
Sign2Speak is a Python-based project that converts Sign Language to Speech in real-time English and Hindi Audio using PyTorch and TTS. 
This project aims to bridge the communication gap between people who use sign language and those who do not, by providing a real-time translation service.

### Key Features
- Real-time conversion of Sign Language to Speech
- Utilizes PyTorch for deep learning models
- TTS (Text-to-Speech) integration for natural speech output
- Easy-to-use API for developers

### Who This Project Is For
- Sign language interpreters
- Developers interested in computer vision and machine learning
- Researchers in the field of sign language recognition
- Anyone looking to improve accessibility

## âœ¨ Features
- ğŸ“Š **Data Analysis**: Tools to analyze and balance datasets
- ğŸ“¹ **Video Processing**: Extract keypoints from videos
- ğŸ§  **Model Training**: Train deep learning models for sign language recognition
- ğŸ¤ **TTS Integration**: Convert recognized signs to natural speech
- ğŸ“ˆ **Evaluation**: Evaluate model performance with detailed metrics

## ğŸ› ï¸ Tech Stack
- **Programming Language**: Python
- **Frameworks**: PyTorch, TTS
- **Libraries**: MediaPipe, OpenCV, Pandas, NumPy
- **Tools**: Jupyter Notebook, GitHub Actions

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8 or later
- PyTorch
- MediaPipe
- OpenCV
- Pandas
- NumPy
- TTS

### Quick Start
```bash
# Clone the repository
git clone https://github.com/yourusername/sign2speak.git

# Make Sure Python is installled, check with the following command:
python --version

# Create a Virtual Environment
python -m venv myenv

# Activate the Virtual Environment
source myenv/bin/activate

# Navigate to the project directory
cd sign2speak

# Install dependencies
pip install -r requirements.txt

# Run the prediction script
python realtime_prediction.py
```

### Alternative Installation Methods
- **Docker**: Use the provided Dockerfile to set up a containerized environment.
- **Virtual Environment**: Create a virtual environment and install dependencies.

## ğŸ¯ Usage

### Basic Usage
```python
# Example of using the model to predict a sign
# Run the file named "realtime_prediction.py"
python realtime_prediction.py

```

**It opens the attached/integrated webcam which waits for the sign language**
**Once the sign language is captured, it is recognized and gets translated into english and hindi audio in the audio directory**


### Advanced Usage
- **Custom Model Training**: Execute the file extract_keypoints_lstm.py -> Opens the Integrated/Attached Camera and captures 
- **Data Augmentation**: Use the `KeypointAugmentation` class to augment keypoints for better training.
- **Evaluation**: Run the `evaluate.py` script to evaluate the model's performance.

## ğŸ“ Project Structure
```
sign2speak/
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ analyze_dataset.py
â”œâ”€â”€ analyze-msasl.py
â”œâ”€â”€ analyze.py
â”œâ”€â”€ download-asl-old_2.py
â”œâ”€â”€ download-asl-old.py
â”œâ”€â”€ download-videos.py
â”œâ”€â”€ extract-keypoints-full.py
â”œâ”€â”€ filtered_annotations_selected_glosses.json
â”œâ”€â”€ filtered_annotations_top_10_old.json
â”œâ”€â”€ model_baseline.py
â”œâ”€â”€ model_transformer.py
â”œâ”€â”€ model.py
â”œâ”€â”€ move_videos.py
â”œâ”€â”€ MSASL_test.json
â”œâ”€â”€ MSASL_train.json
â”œâ”€â”€ MSASL_val.json
â”œâ”€â”€ sign2speech_pipeline_tcn.py
â”œâ”€â”€ updated-filtered-annotations.py
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ unmatched_videos.txt
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataload.py
â”‚   â”œâ”€â”€ deploy.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ training.py
â””â”€â”€ README.md
```

## ğŸ”§ Configuration
- **Configuration Files**: Modify `config.json` for model parameters and other settings.

## ğŸ¤ Contributing
- Fork the repository
- Create a new branch for your feature or bug fix
- Write clean, well-commented code
- Submit a pull request

## ğŸ“ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors & Contributors
- **Maintainers**: Priyabrata Das
- **Contributors**: [List of contributors]

## ğŸ› Issues & Support
- Report issues on the [GitHub Issues page](https://github.com/yourusername/sign2speak/issues)
- Get help on the [GitHub Discussions page](https://github.com/yourusername/sign2speak/discussions)

## ğŸ—ºï¸ Roadmap
- **Future Improvements**:
  - Real-time video processing
  - Mobile app integration
  - Addition of other languages

---

**Badges:**
[![Build Status](https://github.com/yourusername/sign2speak/workflows/CI/badge.svg)](https://github.com/yourusername/sign2speak/actions)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Stars](https://img.shields.io/github/stars/yourusername/sign2speak)](https://github.com/yourusername/sign2speak/stargazers)
[![Forks](https://img.shields.io/github/forks/yourusername/sign2speak)](https://github.com/yourusername/sign2speak/network/members)
